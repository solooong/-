# Ключевые знания о server-realty

Здесь содержится информация о функционале server-realty, а также об основных технологиях и сервисах которые используются
для реализации этого функционала

## Основной функционал приложения

##### Размещение и отображение объявлений по недвижимости

Данную часть проекта можно считать наиболее сложной технически.

Основные данные, с которыми мы работаем:

* данные об объявлениях по продаже квартир, включая фотографии
* данные о жилищных комплексах (ЖК), включая фотографии
* данные о продавцах
* данные о компаниях-застройщиках

Основной функционал в данной сфере:

* Вывод данных об объявлениях с возможностью фильтрации по различным критериям
* Вывод данных о жилищных комплексах (и в том числе о квартирах конкретно в данном ЖК) с возможностью фильтрации по
  различным критериям
* Получение, обработка и хранение данных об объявлениях из фидов. Мониторинг статуса фидов с целью своевременного
  обновления данных
* Возможность добавить либо изменить объявление вручную в личном кабинете клиента (представителей агенств недвижимости и
  застройщиков)
* Обработка изображений, модификация изображений в соответствии с требованиями проекта, хранение изображений
* Вывод подсказок по критериям поиска объявлений и ЖК на основе текстового запроса пользователя
* Сбор статистики по посещениям страниц объявлений и кликам, генерация отчетов о статистике

##### Размещение и отображение новостных статей

* Вывод данных новостных статей
* Поиск статей по текстовому запросу, фильтрация
* Возможность редактировать, сохранять и публиковать новостные статьи в кабинете журналиста
* Возможность отложенной публикации статьи в указанную дату

##### Размещение на других порталах, лидогенерация

* Редирект телефонного номера объявления через виртуальную АТС. Сбор статистики по звонкам.
* Хранение информации о модификациях дизайна для каждого конкретного портала
* Возможность пользователя оставить контактную информацию, пересылка этой информации потребителям лидов по e-mail

## Основные зависимости:

#### [Django](https://www.djangoproject.com/)

Веб-фреймворк. В основном используется для работы с данными в базе с помощью django ORM.

#### [Celery](https://docs.celeryproject.org/en/stable/)

Очередь задач. Позволяет распределять задачи по различным воркерам через брокер сообщений. В нашем случае в качестве
брокера используем Redis. Примеры задач в нашем проекте - обработка фида, обработка изображения, удаление фида.

Мы распределяем задачи по нескольким очередям, и указываем для всех воркеров из каких именно очередей они будут брать
задачи. Это позволяет нам выделять на ресурсоемкие задачи больше вычислительных мощностей, а также позволяет
удостовериться, что исполнение высокоприоритетных задач не будет задерживаться из-за того, что очередь забита менее
важными задачами.

#### [Celery-beat](https://docs.celeryproject.org/en/stable/userguide/periodic-tasks.html)

Надстройка над celery, которая позволяет планировать выполнение задачи на определенное время, а также выполнять задачи
регулярно с определённым интервалом. Пример регулярной задачи в нашем проекте - мониторинг фида.

#### [Cacheops](https://github.com/Suor/django-cacheops)

Кэш для запросов django ORM на основе redis. Есть некоторые правила, которые нужно соблюдать, чтобы обеспечить
совместимость проекта с cacheops; о них можно прочитать в [документации о принятых решениях](Документация/10.%20server-realty/doc/decisions.md).

#### [Ariadne GraphQl](https://ariadnegraphql.org/)

Реализация сервера для языка запросов [GraphQL](http://graphql.github.io/). Используется для реализации эндпойнта нашего
api. Данную библиотеку выбрали, так как она использует
подход [schema-first](https://blog.logrocket.com/code-first-vs-schema-first-development-graphql/), а также потому что
она более активно развивается и более удобна в использовании чем главная
альтернатива ([graphene](https://docs.graphene-python.org/en/latest/)).

#### [Python dependency injector](https://python-dependency-injector.ets-labs.org/)

Фреймворк для инъекции зависимостей. Позволяет не завязываться на конкретные имплементации сервисов и не думать об их
инициализации в местах использования. Также облегчает работу с общим состоянием (в основном это различные кэши), а также
предоставляет удобное апи для замещения настоящих имплементаций моками в тестах.

#### [Pydantic](https://pydantic-docs.helpmanual.io/)

Библиотека для описания моделей данных с валидацией типов в рантайме. Используется в основном для описания моделей
данных предметной области.

## Организация кода

#### Структура папок и организация компонентов

В данном проекте используется гибридный подход, сочетающий в себе
идеи [n-tier architecture](https://en.wikipedia.org/wiki/Multitier_architecture)
и [vertical slice architecture](https://mehdihadeli.github.io/awesome-software-architecture/architectural-style/vertical-slice-architecture/)
с предпочтением в сторону второго. Грубо говоря, мы хотим по возможности группировать код по связи с определённой
бизнес-задачей или группой задач прежде чем мы группируем его по принадлежности к определённому слою абстракции. Чем
больше бизнес-задач использую код, тем больше мы хотим разделять его на слои.

Структура папок выглядит следующим образом:

* `core\shared`
    * разбит на подпапки в соответствии со слоями абстракции
    * для кода который используется повсеместно и не вписывается в отдельную сферу предметной области
    * Что импортирует
        * только то, что также находится в `core\shared`
    * Где может импортироваться
        * из любого места кодовой базы
* `core\components`
    * разбит на модули или подпапки, каждая из которых соответствует отдельному компоненту
    * для кода который используются для решения какой-то группы задач, объединённой функционалом либо сферой предметной
      области
    * Что импортирует
        * каждый компонент знает только про то, что находится в `core\shared`
        * компонент не должен знать про другие компоненты
    * Откуда может импортироваться
        * из `core\queries` и `core\commands`
* `core\queries` и `core\commands`
    * разбит на модули или подпапки, каждая из которых соответствует отдельной задаче
    * для кода связанного с решением конкретных бизнес-задач
    * Что импортирует
        * Код каждой задачи может импортировать код из `core\shared` и `core\components`
        * Код одной задачи не должен знать про другие задачи
    * Откуда может импортироваться
        * Ниоткуда, в том числе не из других задач в `core\queries` и `core\commands`
        * Наличие кода в `core\queries` и `core\commands` - сигнал о том, что этот код используется для решения одной
          задачи и нигде больше
    * на этом уровне наиболее расслаблены требования по разделению на слои абстракции

#### Почему не делать так как говорит django?

В данном проекте используется фреймворк django. Django проверен временем, он популярен и активно поддерживается. В
интернете доступно большое количество материалов по работе с django и большое количество библиотек, которые либо
заточены под взаимодействие с ним либо по меньшей мере рассматривают интеграцию с ним как один из основных вариантов
использования (и соответственно тестируют этот вариант и описывают его в документации).

Ранее мы пытались следовать рекомендациям по организации проекта django. Однако на практике оказалось, что мы используем
ограниченный набор возможностей django, а именно - ORM, middlewares и автоматически сгенерированные админки. Более того,
основная часть нашего кода решает задачи, не требующие взаимодействия с django и раскидывать его по django apps было не
очень удобно. Поэтому несмотря на то, что мы пользуемся этим фреймворком, мы не хотим брать его рекомендованную
структуру за основу проекта.

## Принципы работы с тестами

При написании тестов
используем [Лондонскую парадигму тестирования](https://freecontent.manning.com/what-is-a-unit-test-part-2-classical-vs-london-schools/)

## Детали работы с данными о недвижимости

### Данные об объявлениях и продавцах

#### Фид объявлений

На данный момент единственным поддерживаемым источником данных об объявлениях является фид объявлений. Фид - XML-файл,
содержащий информацию о наборе объявлений
в [общепринятом формате](https://yandex.ru/support/realty/rules/content-requirements.html). Также фидом может называться
ссылка, по который находится актуальная версия данного файла. Пример фида от застройщика
"Расцветай" можно увидеть [здесь](https://pb5903.profitbase.ru/export/yandex/3ab0d15ef7b6ab570de504ef8fddf9db).

#### Мониторинг фида

Для поддержки актуальности данных из фида мы периодически проверяем обновились ли в нём данные - смотрим на таймстамп
последнего обновления фида по ссылке и сверяем с таймстампом последнего обновления в нашей базе. Если зарегистрировали
обновление фида - запускаем задачу обработки и синхронизации с базой.

#### Обработка фида

Обработка фида проходит в несколько этапов:

* Скачиваем фид
* Конвертируем сырые данных из дерева элементов XML в набор объектов заданных типов (правила приведения типов описаны
  в `offers/tasks/feed/processor/schema_definitions.py`), валидируем значения отдельных элементов
* Валидируем объявления целиком согласно правилам предметной области
* Дополняем данные (добавляем цену за квадратный метр, нормализованные данные об адресе, и т.п.)

В фиде данные об адресе продаваемых квартир указаны одной строкой, при этом там могут присутствовать ошибки и нет
строгих ограничений по формату этой строки. Соответственно, перед нами стоит задачи нормализации этих данных и
приведения их к единому формату. Для этого мы используем сторонний сервис [dadata](https://dadata.ru/) который умеет
парсить адреса из сырого текстового ввода, сопоставляет эти адреса с id в государственном адресном реестре ФИАС, а также
предоставляет данные о геопозиции (не во всех случаях). Для взаимодействия с сервисом используется
их [библиотека](https://github.com/hflabs/dadata-py).

Поскольку запросы разбора адресов в dadata оплачиваются поштучно, мы кэшируем их в redis. Для этого используется
библиотека `requests-cache`.

#### Синхронизация данных фида с базой

Конвертируем набор обработанных данных из фида в объекты моделей. Сопоставляем набор моделей из актуального фида с
текущими записями в базе; создаём новые записи, удаляем старые, при наличии обновлений модифицируем существующие. Для
оптимизации запросов в базу используется модифицированный код
библиотеки [django-bulk-sync](https://github.com/mathandpencil/django-bulk-sync).

При конверсии данных в объекты моделей нам важно, чтобы не было дубликатов моделей с одинаковыми наборами данных. Для
этого реализован механизм `GenericUniqueModelInstanceFactory`, задача которого - связывать множество копий набора данных
с единственной копией модели. Этот механизм преобразует набор данных в хэшируемый ключ, который и является
идентификатором данного набора. В `django-bulk-sync` аналогичный механизм используется для сопоставления новых данных с
данными существующими в базе.

### Данные о ЖК и застройщиках

Данные о ЖК и застройщиках добавляются через запрос api. Изображения ЖК обрабатываются аналогично изображениям из фида.

## Загрузка, обработка и хранение изображений

В фиде присутствуют ссылки на изображения - фотографии объектов недвижимости, логотипы застройщиков, и т. д. Мы
выгружаем эти изображения, модифицируем их с помощью библиотеки `pillow` (меняем размеры, добавляем ватермарки) и
загружаем
на [Object Storage](https://cloud.yandex.ru/docs/storage/quickstart?utm_source=console&utm_medium=side-bar-left&utm_campaign=storage)
. Каждое изображение обрабатывается и хранится в нескольких вариантах (например, маленькие вариант для отображения в
списке объявлений, большой вариант с ватермаркой для страницы объявления).

Формат ссылки на изображение в object storage:

`https://storage.yandexcloud.net/<bucket>/images/<image-category>/<group-id>/<image-id>/<image-variant-size>.jpg`

- `bucket` - идентификатор бакета в object storage. Подробности про бакеты
  в [документации Яндекс.Облако](https://cloud.yandex.ru/docs/storage/concepts/bucket).
- `image-category` - идентификатор категории изображений (например, фото объявления, фото ЖК, логотип застройщика).
- `group-id` - идентификатор группы изображений. В случае с фото из обьявлений
  это [uuid5](https://docs.python.org/3/library/uuid.html#uuid.uuid5), сгенерированный на основе ссылки на фид из
  которого получено данное объявление. Другими словами, мы группируем фото объявлений в object storage по фидам. Не все
  категории изображений разбиваются на подгруппы; для некоторых (например, фото/логотипы продавцов) эта часть ссылки
  отсутствует.
- `image-id` - идентификатор уникального изображения. Для всех изображений это uuid, сгенерированный на основе исходной
  ссылки на изображение
- `<image-variant-size>` - размер данного варианта изображения

Пример ссылки на фото объявления в object storage:

`https://storage.yandexcloud.net/tayga-city-images-dev/images/offer/cafa7ba4-cbf5-5002-b55b-d5ac1e84604d/95170868-7c68-5644-a6b6-1bb301834370/960.jpg`

Зная категорию изображения, его uuid и id группы к которой он принадлежит (например, uuid фида) можно построить список
ссылок на все существующие варианты для данного изображения. Из-за этого мы храним в базе только uuid изображения - это
занимает меньше места, плюс можно добавлять, удалять или модифицировать набор вариантов изображения без изменения данных
в базе. Поскольку uuid изображения является прямым следствием ссылки на изображения, наша система не поддерживает
ситуации когда изображение изменяется, но ссылка остаётся прежней.

Процесс синхронизации изображений в object storage с актуальными данными из фида аналогичен процессу синхронизации
данных с базой: Мы запрашиваем из object storage набор всех изображений связанных с данным фидом и сравниваем этот набор
с актуальными данными из обрабатываемого фида. Фото которых больше нет в фиде удаляются из object storage. Для фото
которые есть в фиде, но отсутствуют в object storage запускается процесс обработки (создаётся задача celery). Для
взаимодействия с object storage используется библиотека
[boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) - это враппер для api AWS, однако поскольку
api Яндекс облако во всём копирует AWS, то и библиотеки для AWS также с ним работают.

Процесс обработки фото относительно ресурсоёмкий - одно фото занимает 5-10 секунд. Кроме того, при обновлении фида
обычно появляется несколько новых фотографий сразу. На практике это значит, что часто возникают ситуации когда данные о
фото появились в базе, но при этом обработанные варианты фото в object storage отсутствуют. Мы хотим распознавать такие
ситуации чтобы не отправлять в ответах на запросы сломанные ссылки на object storage, а вместо этого показывать на месте
фото временную заглушку с пометкой "фото обрабатывается". Для этого в базе также хранится пометка о статусе обработки
изображения. Когда обработка завершается успешно - изображение помечается в базе как обработанное. При неудачной
обработке запись об изображении удаляется из базы.

## Вывод данных

На данный момент выдача данных происходит через эндпойнт api, реализованный на основе языка запросов
[GraphQL](https://graphql.org/learn/). Основные понятия GraphQL, которые следует знать: запрос, мутация, резолвер, поле,
тип, инпут, SDL-схема.

Схема является единственным источником правды для нашего api. Документация отдельных запросов также является её частью.
Поскольку схема используется как фронтендом, так и бэкендом, она находится в корне проекта
(`/graphql-schema/schema.graphql`). При сборке контейнера `server-realty-base` она копируется во внутреннюю директорию.

Специфика механизма обработки запроса GraphQL приводит к так
называемой [проблеме N+1](https://medium.com/the-marcy-lab-school/what-is-the-n-1-problem-in-graphql-dd4921cb3c1a) -
один запрос GraphQL может генерировать чрезмерно много запросов к базе данных. На данный момент для решения этой
проблемы для каждого запроса GraphQL мы пишем кастомный запрос к базе который с помощью нескольких JOIN заранее
подтягивает все необходимые данные.

Чтобы гарантировать соответствие схем источника запроса и бэкенда реализован механизм валидации схемы. Если в запросе
присутствует заголовок `Graphql-Schema-Hash`, то при обработке запроса на бэкенде значение этого заголовка сверяется с
md5-хэшем текущей схемы, который вычисляется при сборке контейнера `server-realty-base`.

Для реализации jwt-аутентификации используется присвоенный код библиотеки `django-ariadne-jwt`.
